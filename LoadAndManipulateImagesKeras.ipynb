{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1c66c7-8998-45b2-b2d6-b747002f23a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "JPEG\n",
      "RGB\n",
      "(640, 427)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "img = load_img('bondi_beach.jpg')\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471afc94-db35-4fa9-b8c8-13c9881c658f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "float32\n",
      "(427, 640, 3)\n",
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "img = load_img('bondi_beach.jpg')\n",
    "print(type(img))\n",
    "\n",
    "img_array = img_to_array(img)\n",
    "print(img_array.dtype)\n",
    "print(img_array.shape)\n",
    "\n",
    "img_pil = array_to_img(img_array)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020fa8c1-61dd-4677-8515-7fdef678b525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "None\n",
      "RGB\n",
      "(640, 427)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "img = load_img('bondi_beach.jpg', color_mode='grayscale')\n",
    "\n",
    "img_array = img_to_array(img)\n",
    "\n",
    "save_img('bondi_beach_grayscale.jpg', img_array)\n",
    "\n",
    "img = load_img('bondi_beach_grayscale.jpg')\n",
    "\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163dd7f4-e46c-454a-b175-2933e3a02f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26e01ca-8832-470f-b86b-7254b8eef600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (60000, 28, 28) (60000,)\n",
      "Test ((10000, 28, 28), (10000,))\n",
      "Train 0 255 33.318421449829934 78.56748998339798\n",
      "Test 0 255 33.791224489795916 79.17246322228644\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "# load dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# summarize dataset shape\n",
    "print('Train', train_images.shape, train_labels.shape)\n",
    "print('Test', (test_images.shape, test_labels.shape))\n",
    "# summarize pixel values\n",
    "print('Train', train_images.min(), train_images.max(), train_images.mean(),\n",
    "train_images.std())\n",
    "print('Test', test_images.min(), test_images.max(), test_images.mean(), test_images.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec8a61a-777e-443e-a8e2-2f2d05655080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b027d575-2409-415e-8c9b-76c70990e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a90db6f-339f-4362-973a-8ddea8ea2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "894c8625-57b6-49ce-ab92-a26a82113650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(trainX, trainY), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "614b8239-f48b-4018-9c97-0b1f65780520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min=0.000, max=255.000\n",
      "Test min=0.000, max=255.000\n",
      "Batches train=938, test=157\n",
      "Batch shape=(64, 28, 28, 1), min=0.000, max=1.000\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# load dataset\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "# confirm scale of pixels\n",
    "print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\n",
    "print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\n",
    "# create generator (1.0/255.0 = 0.003921568627451)\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "# Note: there is no need to fit the generator in this case\n",
    "# prepare a iterators to scale images\n",
    "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
    "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
    "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
    "# confirm the scaling works\n",
    "# Obtener el siguiente lote usando `next`\n",
    "batchX, batchy = next(train_iterator)\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d798501c-78fd-43f9-b1c6-b714f8731840",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "408de81f-9daf-4e2e-8c27-0c9b9421baa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean after normalization:  tf.Tensor(-3.2552084e-08, shape=(), dtype=float32)\n",
      "Train std after normalization:  tf.Tensor(1.0000004, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Normalization\n",
    "\n",
    "# Crea el normalizador\n",
    "normalizer = Normalization(axis=-1)\n",
    "\n",
    "# Ajusta el normalizador usando el dataset de entrenamiento\n",
    "normalizer.adapt(trainX)\n",
    "\n",
    "# Aplica el normalizador al dataset\n",
    "trainX_normalized = normalizer(trainX)\n",
    "testX_normalized = normalizer(testX)\n",
    "\n",
    "# Verifica la normalización\n",
    "print(\"Train mean after normalization: \", tf.reduce_mean(trainX_normalized))\n",
    "print(\"Train std after normalization: \", tf.math.reduce_std(trainX_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d226f4b-d9dd-41af-a501-bed21dc591d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[33.318447]]]\n"
     ]
    }
   ],
   "source": [
    "print(datagen.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78385079-35cf-433e-8e46-afe1370f0ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means train=33.318, test=33.791\n",
      "Data Generator Mean: 33.318\n",
      "(64, 28, 28, 1) -2.0745666\n",
      "(60000, 28, 28, 1) -1.9512918e-05\n"
     ]
    }
   ],
   "source": [
    "# example of centering a image dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "# report per-image mean\n",
    "print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator Mean: %.3f' % datagen.mean)\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "# get a batch\n",
    "batchX, batchy = next(iterator)\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape, batchX.mean())\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "# get a batch\n",
    "batchX, batchy = next(iterator)\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape, batchX.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf81aaf6-aee2-4458-bc6c-052538649858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
      "Data Generator mean=33.318, std=78.567\n",
      "(64, 28, 28, 1) 0.028578594 1.0304241\n",
      "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "# report pixel means and standard deviations\n",
    "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(),\n",
    "testX.mean(), testX.std()))\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "# get a batch\n",
    "batchX, batchy = next(iterator)\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "# get a batch\n",
    "batchX, batchy = next(iterator)\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99d85fa0-09a1-4109-9a4b-96cf3c871c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics train=33.318 (78.567), test=33.791 (79.172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\cursoDeepLearning\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1047: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZCA Whitening aplicado.\n",
      "(64, 28, 28, 1) 16.989561 277.70584\n",
      "(60000, 28, 28, 1) 16.993118 277.70798\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Cargar el dataset MNIST\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "# Reformatear las imágenes para incluir un canal\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "\n",
    "# Imprimir estadísticas iniciales del dataset\n",
    "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
    "\n",
    "# Crear generador que aplica ZCA Whitening\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "\n",
    "# Ajustar el generador para calcular los componentes de ZCA\n",
    "datagen.fit(trainX)\n",
    "\n",
    "# Mostrar estadísticas adicionales\n",
    "print('ZCA Whitening aplicado.')\n",
    "\n",
    "# Demostrar el efecto en un único lote\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "batchX, batchy = next(iterator)\n",
    "\n",
    "# Estadísticas del lote\n",
    "print(batchX.shape, batchX.mean(), batchX.std())\n",
    "\n",
    "# Demostrar el efecto en todo el dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "batchX, batchy = next(iterator)\n",
    "\n",
    "# Estadísticas del dataset completo\n",
    "print(batchX.shape, batchX.mean(), batchX.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd84aeeb-90bf-47b5-bd85-5b9d19b199da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample-Wise Centering:\n",
      "Image mean (after centering): 0.000\n",
      "\n",
      "Sample-Wise Standardization:\n",
      "Image mean (after standardization): 0.000\n",
      "Image std (after standardization): 1.000\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Cargar el dataset MNIST\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "# Reformatear las imágenes para incluir un canal\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\n",
    "# Crear generador para sample-wise centering\n",
    "datagen_centering = ImageDataGenerator(samplewise_center=True)\n",
    "\n",
    "# Crear generador para sample-wise standardization\n",
    "datagen_standardization = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
    "\n",
    "# Ejemplo de centering\n",
    "print(\"Sample-Wise Centering:\")\n",
    "iterator_centering = datagen_centering.flow(trainX, trainy, batch_size=1, shuffle=False)\n",
    "batchX, batchy = next(iterator_centering)\n",
    "print(f\"Image mean (after centering): {batchX.mean():.3f}\")\n",
    "\n",
    "# Ejemplo de standardization\n",
    "print(\"\\nSample-Wise Standardization:\")\n",
    "iterator_standardization = datagen_standardization.flow(trainX, trainy, batch_size=1, shuffle=False)\n",
    "batchX, batchy = next(iterator_standardization)\n",
    "print(f\"Image mean (after standardization): {batchX.mean():.3f}\")\n",
    "print(f\"Image std (after standardization): {batchX.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf14d063-708a-4fab-a0a3-f9c203978e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 0us/step\n",
      "Dataset shapes - Train: (50000, 32, 32, 3), Test: (10000, 32, 32, 3)\n",
      "Batch shape: (64, 32, 32, 3)\n",
      "Min pixel value: 0.000, Max pixel value: 1.000\n",
      "Red channel - Min: 0.000, Max: 1.000\n",
      "Green channel - Min: 0.000, Max: 1.000\n",
      "Blue channel - Min: 0.000, Max: 1.000\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "# Cargar el dataset CIFAR-10\n",
    "(trainX, trainy), (testX, testy) = cifar10.load_data()\n",
    "\n",
    "# Verificar la forma del dataset\n",
    "print(f\"Dataset shapes - Train: {trainX.shape}, Test: {testX.shape}\")\n",
    "\n",
    "# Crear generador con escalado simple (rescale)\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Crear un iterador para preprocesar imágenes\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "\n",
    "# Obtener un batch de imágenes procesadas\n",
    "batchX, batchy = next(iterator)\n",
    "\n",
    "# Confirmar el escalado de píxeles\n",
    "print(f\"Batch shape: {batchX.shape}\")\n",
    "print(f\"Min pixel value: {batchX.min():.3f}, Max pixel value: {batchX.max():.3f}\")\n",
    "\n",
    "# Confirmar el escalado por canal\n",
    "red_channel = batchX[..., 0]\n",
    "green_channel = batchX[..., 1]\n",
    "blue_channel = batchX[..., 2]\n",
    "\n",
    "print(f\"Red channel - Min: {red_channel.min():.3f}, Max: {red_channel.max():.3f}\")\n",
    "print(f\"Green channel - Min: {green_channel.min():.3f}, Max: {green_channel.max():.3f}\")\n",
    "print(f\"Blue channel - Min: {blue_channel.min():.3f}, Max: {blue_channel.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f10aaae-e3c5-47ed-acc6-b9f8b7a9ee30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
